# Procesador de Documentos PDF/PPT

Sistema modular para extraer y analizar contenido de documentos PDF y PowerPoint usando IA (Claude/OpenAI) con filtrado inteligente de im√°genes y prompts especializados por dominio.

## üöÄ Caracter√≠sticas

- ‚úÖ Extracci√≥n de texto de PDF y PPTX
- ‚úÖ Extracci√≥n de im√°genes y gr√°ficos
- ‚úÖ **Filtrado inteligente de im√°genes con OCR** (descarta decoraciones sin valor)
- ‚úÖ **Sistema de relevancia** (0-1) para filtrar contenido sin valor anal√≠tico
- ‚úÖ **Detecci√≥n de gr√°ficos compuestos** (imagen + texto renderizado separado)
- ‚úÖ An√°lisis de gr√°ficos con IA usando Pydantic-AI (Claude o OpenAI)
- ‚úÖ **Clasificaci√≥n de insights**: Hallazgos (cuantitativos) vs Hip√≥tesis (cualitativos) vs Observaciones (metodol√≥gicas)
- ‚úÖ **Sistema de prompts modular** (base + contexto de dominio v√≠a CLI)
- ‚úÖ **Configuraci√≥n gen√©rica y reutilizable** entre empresas
- ‚úÖ **Contextos especializados opcionales** (AFP Chile, sector financiero, etc.)
- ‚úÖ **Res√∫menes Markdown filtrados** por relevancia y tipo de insight
- ‚úÖ Identificaci√≥n autom√°tica de m√©tricas y porcentajes
- ‚úÖ Configuraci√≥n externalizada en JSON
- ‚úÖ C√≥digo simple y mantenible

## üì¶ Instalaci√≥n

```bash
pip install -r requirements.txt
```

### Requisitos adicionales

#### 1. Tesseract OCR (Obligatorio)

Para el filtrado de im√°genes, instala Tesseract:

**Windows:**
```powershell
# Con chocolatey
choco install tesseract

# O descargar desde: https://github.com/UB-Mannheim/tesseract/wiki
```

**macOS:**
```bash
brew install tesseract
```

**Linux:**
```bash
sudo apt-get install tesseract-ocr
```

#### 2. LibreOffice (Para procesar PPTX)

Si necesitas procesar archivos PowerPoint (.pptx), instala LibreOffice:

**Windows:**
```powershell
# Con chocolatey (recomendado)
choco install libreoffice

# O descargar desde: https://www.libreoffice.org/download/download/
```

**macOS:**
```bash
brew install --cask libreoffice
```

**Linux:**
```bash
sudo apt-get install libreoffice
```

**Alternativa en Windows:** Si tienes Microsoft PowerPoint instalado, el sistema lo usar√° autom√°ticamente (mayor calidad).

**Verificar instalaci√≥n:**
```bash
# Deber√≠a mostrar la versi√≥n instalada
soffice --version
```

## üîß Configuraci√≥n

### 1. API Keys

El sistema busca las API keys en este orden de prioridad:

**Opci√≥n 1 (Recomendada)** - Variables de entorno:

```powershell
# Windows PowerShell - Temporal (sesi√≥n actual)
$env:OPENAI_API_KEY = "sk-..."
$env:ANTHROPIC_API_KEY = "sk-ant-..."

# Windows PowerShell - Permanente
[System.Environment]::SetEnvironmentVariable('OPENAI_API_KEY', 'sk-...', 'User')
[System.Environment]::SetEnvironmentVariable('ANTHROPIC_API_KEY', 'sk-ant-...', 'User')
```

```bash
# Linux/Mac - Temporal
export OPENAI_API_KEY='sk-...'
export ANTHROPIC_API_KEY='sk-ant-...'

# Linux/Mac - Permanente (agregar a ~/.bashrc o ~/.zshrc)
echo 'export OPENAI_API_KEY="sk-..."' >> ~/.bashrc
echo 'export ANTHROPIC_API_KEY="sk-ant-..."' >> ~/.bashrc
```

**Opci√≥n 2** - En `config.json` (no recomendado para repositorios compartidos):

```json
{
  "analysis": {
    "provider": "openai",
    "openai_api_key": "sk-...",
    "anthropic_api_key": "sk-ant-..."
  }
}
```

‚ö†Ô∏è **Importante**: Si usas `config.json` para las keys, no subas el archivo a Git. Usa `private_config.json` y agr√©galo al `.gitignore`.

### 2. Seleccionar Proveedor y Modelo

Edita `config.json`:

```json
{
  "analysis": {
    "provider": "openai",              // o "anthropic"
    "model": "gpt-4o",                 // o "claude-3-5-sonnet-20241022"
    "analyze_text_with_ai": false,     // Analizar p√°ginas de texto (lento)
    "relevance_threshold": 0.5,        // Umbral para insights (0-1)
    "insight_filter": "actionable",    // Tipo de insights a mostrar
    "show_insight_classification": true // Mostrar iconos de clasificaci√≥n
  }
}
```

**Modelos soportados:**

**OpenAI:**
- `gpt-4o` (recomendado para visi√≥n)
- `gpt-4o-mini` (m√°s econ√≥mico)
- `gpt-4-turbo`
- `o1-preview`, `o1-mini` (razonamiento avanzado)

**Anthropic:**
- `claude-3-5-sonnet-20241022` (recomendado)
- `claude-3-5-haiku-20241022` (m√°s r√°pido)
- `claude-3-opus-20240229` (m√°xima calidad)

### 3. Configuraci√≥n del Filtro de Im√°genes

El sistema usa OCR para determinar si una imagen contiene informaci√≥n valiosa:

```json
{
  "extraction": {
    "image_filter": {
      "enabled": true,
      "min_chars": 15,          // M√≠nimo caracteres para considerar valiosa
      "min_digits": 3,          // M√≠nimo n√∫meros requeridos
      "min_words": 5,           // M√≠nimo palabras √∫tiles
      "require_numbers": false, // Si true, rechaza im√°genes sin n√∫meros
      "ignore_words": [         // Palabras que no cuentan como "√∫tiles"
        "logo", "www", "com", "http", "https",
        "copyright", "derechos", "reservados"
      ]
    }
  }
}
```

**Para casos espec√≠ficos**, puedes agregar palabras a `ignore_words`:
- Nombres de empresas comunes en tus documentos
- Esl√≥ganes repetitivos
- T√©rminos legales est√°ndar

### 4. Detecci√≥n de Gr√°ficos Compuestos

Algunos PDFs renderizan gr√°ficos donde las barras/l√≠neas son im√°genes pero los valores num√©ricos est√°n como texto separado. El sistema detecta autom√°ticamente estos casos y enriquece el an√°lisis:

```json
{
  "extraction": {
    "composite_detection": {
      "enabled": true,
      "proximity_margin": 50,      // Margen en puntos para buscar texto cercano
      "min_chart_width": 200,      // Ancho m√≠nimo para considerar como gr√°fico
      "min_chart_height": 150,     // Alto m√≠nimo para considerar como gr√°fico
      "min_page_ratio": 0.1,       // Ratio m√≠nimo respecto a la p√°gina
      "min_nearby_numbers": 3,     // M√≠nimo n√∫meros en texto cercano
      "ocr_number_threshold": 2,   // Si OCR detecta menos n√∫meros, es candidato
      "verbose": true
    }
  }
}
```

**¬øC√≥mo funciona?**
1. Extrae las posiciones (bounding boxes) de las im√°genes en el PDF
2. Extrae el texto con coordenadas de cada p√°gina
3. Identifica texto que est√° superpuesto o cercano a cada imagen
4. Si la imagen parece un gr√°fico (por dimensiones) y hay n√∫meros en el texto cercano, 
   pero el OCR de la imagen detect√≥ pocos n√∫meros ‚Üí es un gr√°fico compuesto
5. Al analizar con IA, se incluye el texto extra√≠do como contexto adicional

### 5. Conversi√≥n Autom√°tica de PowerPoint (PPTX ‚Üí PDF)

El sistema convierte autom√°ticamente archivos PPTX a PDF antes del an√°lisis, aprovechando todo el pipeline existente (incluyendo detecci√≥n de gr√°ficos compuestos):

```json
{
  "extraction": {
    "pptx_conversion": {
      "enabled": true,
      "backend": "auto",          // "auto", "libreoffice", o "powerpoint"
      "dpi": 300,                 // Resoluci√≥n de conversi√≥n (mayor = mejor calidad)
      "delete_temp_pdf": false,   // Si eliminar PDF temporal despu√©s del an√°lisis
      "temp_dir": "output/temp_pdfs"  // Directorio para PDFs temporales
    }
  }
}
```

**Backends disponibles:**

| Backend | Requisito | Calidad | Plataforma |
|---------|-----------|---------|------------|
| `libreoffice` | LibreOffice instalado | Muy buena | Windows/Mac/Linux |
| `powerpoint` | Microsoft PowerPoint | Excelente | Solo Windows |
| `auto` | Detecta autom√°ticamente | - | Todas (preferencia: PowerPoint ‚Üí LibreOffice) |

**¬øC√≥mo funciona?**
1. Detecta archivos `.pptx` al procesar
2. Convierte a PDF usando el backend disponible
3. Guarda el PDF en `temp_dir` (default: `output/temp_pdfs/`)
4. Procesa el PDF normalmente con todo el pipeline
5. Opcionalmente elimina el PDF temporal si `delete_temp_pdf: true`

**Ventajas:**
- ‚úÖ Aprovecha toda la infraestructura de an√°lisis de PDFs
- ‚úÖ Detecta gr√°ficos compuestos en presentaciones
- ‚úÖ Mantiene alta calidad de conversi√≥n (DPI configurable)
- ‚úÖ Funciona autom√°ticamente sin intervenci√≥n manual

**Nota:** Se recomienda `delete_temp_pdf: false` para debugging. Si algo falla, puedes revisar el PDF generado.

### 6. Clasificaci√≥n de Insights y Filtrado

El sistema clasifica cada insight en tres categor√≠as seg√∫n su valor anal√≠tico:

| Clasificaci√≥n | Icono | Descripci√≥n | Ejemplo |
|---------------|-------|-------------|---------|
| **Finding** (Hallazgo) | üìä | Respaldado por datos cuantitativos con N ‚â• 100 | "N=1260 casos con satisfacci√≥n de 68%" |
| **Hypothesis** (Hip√≥tesis) | üí° | Observaci√≥n cualitativa que requiere validaci√≥n | "Los usuarios reportan confusi√≥n con el proceso" |
| **Observation** (Observaci√≥n) | üìù | Descripci√≥n metodol√≥gica/contextual sin valor anal√≠tico | "El estudio utiliza encuestas telef√≥nicas" |

**Configuraci√≥n del filtro:**

```json
{
  "analysis": {
    "relevance_threshold": 0.5,        // Solo insights con score ‚â• 0.5
    "insight_filter": "actionable",    // Tipo de insights a incluir
    "show_insight_classification": true // Mostrar iconos y etiquetas
  }
}
```

**Opciones de `insight_filter`:**

| Valor | Qu√© muestra en el resumen Markdown |
|-------|-----------------------------------|
| `"all"` | Todos (hallazgos + hip√≥tesis + observaciones) |
| `"findings"` | Solo hallazgos cuantitativos |
| `"hypotheses"` | Solo hip√≥tesis exploratorias |
| `"observations"` | Solo observaciones metodol√≥gicas |
| **`"actionable"`** | **Hallazgos + hip√≥tesis (excluye observaciones) ‚Üê Recomendado** |

**¬øPor qu√© usar `"actionable"`?**  
Las observaciones metodol√≥gicas ("El estudio abarca 2015-2025", "La muestra incluye mayores de 18 a√±os") tienen valor documental pero NO son insights accionables. El filtro `actionable` las excluye del resumen manteniendo solo conclusiones √∫tiles.

**C√≥mo funcionan los umbrales:**

- `relevance_threshold`: Filtra contenido de baja relevancia (0.0 = basura, 1.0 = altamente relevante)
- Los insights con `relevance_score < threshold` no aparecen en el Markdown
- El JSON completo siempre preserva TODOS los datos sin filtrado

## üìñ Uso

### Ejemplos B√°sicos

```bash
# An√°lisis gen√©rico de PDF (sin contexto de dominio)
python main.py documento.pdf

# Procesar presentaci√≥n PowerPoint (auto-convierte a PDF)
python main.py presentacion.pptx

# Con prompts espec√≠ficos del sector AFP chileno
python main.py informe_afp.pdf --domain-prompts afp_chile

# Procesar PPTX con contexto de dominio
python main.py reporte_afp.pptx --domain-prompts afp_chile

# Con configuraci√≥n personalizada (ej: API keys, filtros personalizados)
python main.py documento.pdf --config private_config.json

# Procesar m√∫ltiples archivos (wildcards)
python main.py *.pdf --domain-prompts afp_chile
python main.py *.pptx --domain-prompts finanzas

# Exportar tambi√©n a formato Word (.docx)
python main.py reporte.pdf --export-docx

# Combinando todas las opciones
python main.py presentacion.pptx --config custom.json --domain-prompts finanzas --export-docx
# Combinando todas las opciones
python main.py presentacion.pptx --config custom.json --domain-prompts finanzas --export-docx

# Solo hallazgos cuantitativos (sin hip√≥tesis ni observaciones)
# Editar config.json: "insight_filter": "findings"
python main.py estudio.pdf --config config.json
```

### Argumentos Disponibles

```
python main.py <archivo(s)> [opciones]

Argumentos posicionales:
  archivo(s)               Ruta(s) al PDF o PPTX a procesar
                          Acepta m√∫ltiples archivos o wildcards (*.pdf, *.pptx)

Opciones:
  --config PATH            Ruta al archivo de configuraci√≥n
                          (default: config.json)
  
  --domain-prompts NOMBRE  Nombre del archivo de prompts de dominio
                          Se busca en prompts/domains/
                          Ejemplo: afp_chile (busca afp_chile.md)
  
  --export-docx            Exportar tambi√©n a tabla Word (.docx)
                          Genera un inventario de conclusiones en formato tabla
```

**Nota sobre PPTX:** Los archivos PowerPoint se convierten autom√°ticamente a PDF antes del an√°lisis. Requiere LibreOffice o PowerPoint instalado (ver secci√≥n de instalaci√≥n).

### Crear Contexto de Dominio Personalizado

1. **Crea un archivo `.md` en `prompts/domains/`:**

```bash
# Ejemplo: prompts/domains/retail.md
```

2. **Define el contexto espec√≠fico:**

```markdown
# CONTEXTO: Sector Retail

## M√©tricas Clave
- Ventas mismo local (SSS)
- Ticket promedio
- Unidades por transacci√≥n (UPT)
- Conversi√≥n
- Margen bruto

## Terminolog√≠a
- POS: Point of Sale
- SKU: Stock Keeping Unit
- Shrinkage: Merma/p√©rdida de inventario
...
```

3. **√ösalo:**

```bash
python main.py reporte_retail.pdf --domain-prompts retail
```

**No necesitas modificar `config.json`** - el sistema busca autom√°ticamente el archivo en `prompts/domains/`.

### Estructura de Prompts

El sistema combina dos niveles de prompts:

```
Prompt Final = Prompt Base + Prompt de Dominio (opcional)
```

- **Prompt Base** (`prompts/base_chart_analysis.md`): Instrucciones generales de an√°lisis
- **Prompt de Dominio** (`prompts/domains/*.md`): Contexto especializado del sector

Ver [prompts/README.md](prompts/README.md) para gu√≠as detalladas.

## üìÅ Estructura de Archivos

```
.
‚îú‚îÄ‚îÄ config.json                    # Configuraci√≥n gen√©rica del sistema
‚îú‚îÄ‚îÄ private_config.json            # (opcional) Config con API keys - no versionar
‚îú‚îÄ‚îÄ models.py                      # Modelos Pydantic
‚îú‚îÄ‚îÄ extractor.py                   # Extracci√≥n de PDF/PPT
‚îú‚îÄ‚îÄ image_filter.py                # Filtrado de im√°genes con OCR
‚îú‚îÄ‚îÄ analyzer.py                    # An√°lisis con IA
‚îú‚îÄ‚îÄ main.py                        # Script principal
‚îú‚îÄ‚îÄ prompts/                       # Sistema de prompts modular
‚îÇ   ‚îú‚îÄ‚îÄ README.md                  # Gu√≠a de prompts
‚îÇ   ‚îú‚îÄ‚îÄ base_chart_analysis.md     # Instrucciones base (gen√©rico)
‚îÇ   ‚îú‚îÄ‚îÄ base_text_analysis.md      # An√°lisis de texto (opcional)
‚îÇ   ‚îî‚îÄ‚îÄ domains/                   # Contextos especializados
‚îÇ       ‚îú‚îÄ‚îÄ afp_chile.md           # Sector AFP Chile
‚îÇ       ‚îî‚îÄ‚îÄ [tu_dominio].md        # Tus contextos personalizados
‚îú‚îÄ‚îÄ requirements.txt               # Dependencias Python
‚îú‚îÄ‚îÄ output/                        # Directorio de salida
    ‚îú‚îÄ‚îÄ images/                    # Im√°genes extra√≠das y filtradas
    ‚îú‚îÄ‚îÄ text/                      # Texto extra√≠do por p√°gina
    ‚îî‚îÄ‚îÄ data/                      # An√°lisis completo
        ‚îú‚îÄ‚îÄ documento_analysis.ndjson       # Claims en formato NDJSON
        ‚îú‚îÄ‚îÄ documento_analysis.docx         # Tabla Word (opcional)
        ‚îî‚îÄ‚îÄ insights-documento.md           # Resumen legible filtrado
```

## üîç Ejemplo de Salida

El sistema genera tres tipos de archivos:

### 1. NDJSON (datos estructurados)

Un JSON por l√≠nea con registros meta/claim/summary:

```ndjson
{"type":"meta","study":{"study_name":"documento.pdf","report_date":null},"extraction":{...}}
{"type":"claim","id":"C001","page_number":5,"classification":"finding","claim_text":"...","evidence":{...}}
{"type":"claim","id":"C002","page_number":5,"classification":"hypothesis","claim_text":"...","evidence":{...}}
{"type":"summary","counts":{"findings":8,"hypotheses":15,"methodological_notes":2},...}
```

Cada claim incluye:
- `id`: Identificador √∫nico (C001, C002...)
- `classification`: `"finding"` | `"hypothesis"` | `"methodological_note"`
- `evidence`: `{n, data_type, base_label}`
- `theme_tags`: Etiquetas tem√°ticas
- `ambiguity_flags`: Indicadores de limitaciones (missing_base, low_n_referential, etc.)

### 2. Tabla Word (.docx) - Opcional

Tabla estructurada para inventario de conclusiones:

| ID | P√°gina | Fecha | Estudio | Tipo | Conclusi√≥n | Datos (N) | Evidencia / limitaciones |
|----|--------|-------|---------|------|------------|-----------|--------------------------|
| C001 | p.5 | 2025-01-13 | documento.pdf | Hallazgo | Satisfacci√≥n neta de 68 puntos | N=1260; Cuantitativo | Relevancia: 0.85 |

Para habilitar:
```bash
# Por l√≠nea de comandos
python main.py documento.pdf --export-docx

# O en config.json
"analysis": {
  "export_docx": true
}
```

### 3. Resumen Markdown (filtrado)

Archivo legible para humanos con insights filtrados:

```markdown
# Insights - documento.pdf

**Fecha de an√°lisis**: 2026-01-13 14:32
**Total p√°ginas**: 56 | **Gr√°ficos analizados**: 12
**Filtro**: Hallazgos + Hip√≥tesis (sin observaciones) | **Umbral relevancia**: 0.5

> üìä **Hallazgo**: Respaldado por datos cuantitativos (N alto)  
> üí° **Hip√≥tesis**: Exploratorio o cualitativo (requiere validaci√≥n)  
> üìù **Observaci√≥n**: Descripci√≥n metodol√≥gica/contextual

## Insights de Gr√°ficos

### 1. Evoluci√≥n de Satisfacci√≥n (l√≠nea)

- üìä **[Hallazgo]** (N=1260) Satisfacci√≥n neta alcanza 68 puntos, +5pp vs semestre anterior
- üí° **[Hip√≥tesis]** La mejora se asocia a reducci√≥n de reclamos en atenci√≥n telef√≥nica

---

**Resumen**: 8 hallazgos | 15 hip√≥tesis
```

**Control del contenido:** Ajusta `relevance_threshold` (0-1) e `insight_filter` en `config.json` para personalizar qu√© aparece en el resumen.

## üõ†Ô∏è Uso Program√°tico

```python
from extractor import DocumentExtractor
from analyzer import DocumentAnalyzer

# Extraer contenido
extractor = DocumentExtractor("config.json")
text_data, image_data = extractor.extract("documento.pdf")

# Analizar gr√°ficos (sin dominio espec√≠fico)
analyzer = DocumentAnalyzer("config.json")
chart_analysis = analyzer.analyze_all_images(image_data)

# Analizar con dominio espec√≠fico
analyzer = DocumentAnalyzer("config.json", domain_prompts_file="afp_chile")
chart_analysis = analyzer.analyze_all_images(image_data)

# Acceder a resultados
for chart in chart_analysis:
    print(f"Tipo: {chart.chart_type}")
    print(f"T√≠tulo: {chart.title}")
    print(f"Insights: {chart.insights}")
```

## üîß Extender la Configuraci√≥n

### Agregar Nuevos Par√°metros

El archivo `config.json` es completamente extensible. Ejemplo:

```json
{
  "extraction": {
    "output_dir": "output",
    "image_dpi": 200,
    "custom_param": "valor"  // ‚Üê Tu par√°metro personalizado
  },
  "analysis": {
    "provider": "openai",
    "model": "gpt-4o",
    "temperature": 0.3,      // ‚Üê Control de creatividad
    "max_tokens": 4000,      // ‚Üê L√≠mite de respuesta
    "verbose": true          // ‚Üê Logging detallado
  },
  "tu_seccion": {            // ‚Üê Nueva secci√≥n completa
    "opcion1": true,
    "opcion2": "valor"
  }
}
```

Luego accede en tu c√≥digo:

```python
from models import Config

config = Config(**json.load(open("config.json")))
custom = config.extraction.get("custom_param")  # "valor"
```

### Crear Configuraciones por Ambiente

```bash
# Desarrollo
python main.py doc.pdf --config config_dev.json

# Producci√≥n
python main.py doc.pdf --config config_prod.json

# Testing
python main.py doc.pdf --config config_test.json
```

Cada archivo puede tener:
- Diferentes proveedores (OpenAI vs Anthropic)
- Diferentes umbrales de filtrado
- Diferentes directorios de salida
- API keys de diferentes cuentas

## üìù Notas T√©cnicas

### Sistema de An√°lisis de Im√°genes

- Las im√°genes se pasan a los modelos usando `BinaryContent` de pydantic-ai
- Soporta m√∫ltiples proveedores (OpenAI, Anthropic) con el mismo c√≥digo
- El filtro OCR descarta im√°genes decorativas (logos, encabezados)
- Solo se analizan im√°genes con contenido informativo (gr√°ficos, tablas)

### Modelos de IA

- **OpenAI**: Requiere `OPENAI_API_KEY` como variable de entorno o en config
- **Anthropic**: Puede funcionar con API key o en modo claude.ai (sin key)
- El c√≥digo verifica que el modelo exista antes de usarlo
- Advertencia si usas modelos beta o no documentados

### Requisitos de Documentos

- Los PDFs deben tener texto extra√≠ble (no escaneos sin OCR previo)
- Las im√°genes deben tener m√≠nimo 100x100 p√≠xeles
- Formatos soportados: PDF, PPT, PPTX
- Im√°genes soportadas: PNG, JPG, JPEG, GIF, WEBP

## ü§ù Personalizaci√≥n y Extensi√≥n

### 1. Agregar Nuevos Formatos de Documento

Extiende `DocumentExtractor` en `extractor.py`:

```python
def extract_docx(self, file_path: str):
    """Extrae contenido de archivos .docx"""
    # Tu implementaci√≥n
    pass
```

### 2. Personalizar An√°lisis

Modifica los modelos en `models.py` para capturar m√°s informaci√≥n:

```python
class InsightItem(BaseModel):
    """Insight con clasificaci√≥n autom√°tica"""
    text: str
    classification: Literal["finding", "hypothesis", "observation"]
    sample_size: Optional[int]
    evidence_type: Optional[Literal["quantitative", "qualitative", "mixed"]]

class ChartData(BaseModel):
    chart_type: str
    title: str
    insights: List[InsightItem]  # Lista de insights clasificados
    relevance_score: float        # Score 0-1 para filtrado
```

### 3. Agregar Nuevos Filtros de Imagen

Extiende `ImageFilter` en `image_filter.py`:

```python
def custom_filter(self, image_path: str) -> bool:
    """Tu l√≥gica de filtrado personalizada"""
    # Ejemplo: detectar logos por colores
    # Ejemplo: clasificar por ML
    pass
```

### 4. Integrar con Otros Proveedores de IA

El sistema usa `pydantic-ai`, que soporta:
- OpenAI
- Anthropic
- Google Gemini
- Mistral
- Groq
- Ollama (local)

Para agregar uno nuevo, solo modifica `_create_model` en `analyzer.py`.

### 5. Crear Pipeline de Procesamiento

```python
# pipeline.py
import json
from pathlib import Path
from main import process_document

# Procesar todos los PDFs de un directorio
docs_dir = Path("documentos/")
for pdf in docs_dir.glob("*.pdf"):
    print(f"Procesando {pdf.name}")
    analysis = process_document(
        str(pdf),
        config_path="config.json",
        domain_prompts_file="afp_chile"
    )
    # Hacer algo con el an√°lisis
    # Por ejemplo: guardar en base de datos, enviar email, etc.
```

## üìä Tipos de Gr√°ficos Soportados

Claude puede analizar:
- Gr√°ficos de barras
- Gr√°ficos de l√≠neas
- Gr√°ficos circulares (pie)
- Tablas de datos
- Gr√°ficos combinados
- Mapas de calor
- Y m√°s...

## üéØ Control de Calidad de Insights

### Sistema de Relevancia

Cada an√°lisis (gr√°fico o texto) recibe un `relevance_score` de 0 a 1:

| Score | Descripci√≥n | Ejemplo |
|-------|-------------|---------|
| **0.7-1.0** | Alta relevancia - Datos cuantitativos, m√©tricas clave | Gr√°fico con KPIs, tabla con resultados de encuesta |
| **0.4-0.7** | Relevancia media - Informaci√≥n descriptiva √∫til | Contexto cualitativo, explicaciones metodol√≥gicas |
| **0.0-0.4** | Baja relevancia - Contenido decorativo o sin valor | Logos, banners, p√°ginas de portada, texto legal |

**Configurar el umbral:**

```json
{
  "analysis": {
    "relevance_threshold": 0.5  // Solo insights ‚â• 0.5 en el resumen
  }
}
```

### Sistema de Clasificaci√≥n

Cada insight se clasifica autom√°ticamente por la IA:

#### üìä Finding (Hallazgo)
- **Cu√°ndo**: Datos cuantitativos con N ‚â• 100, encuestas representativas
- **Ejemplo**: "N=1260 casos muestran satisfacci√≥n de 68%, +5pp vs semestre anterior"
- **Valor**: Alto - Conclusiones generalizables con respaldo estad√≠stico

#### üí° Hypothesis (Hip√≥tesis)
- **Cu√°ndo**: Observaciones cualitativas, N < 50, interpretaciones exploratorias
- **Ejemplo**: "Los usuarios reportan confusi√≥n con el proceso de afiliaci√≥n"
- **Valor**: Medio - Requiere validaci√≥n adicional

#### üìù Observation (Observaci√≥n)
- **Cu√°ndo**: Informaci√≥n metodol√≥gica, contexto del estudio, descripciones procedimentales
- **Ejemplo**: "El estudio utiliza encuestas telef√≥nicas en comunas urbanas con poblaci√≥n >130K"
- **Valor**: Documental - No es una conclusi√≥n, solo describe c√≥mo se hizo el estudio

### Filtrado Recomendado

Para an√°lisis ejecutivo, usa:

```json
{
  "analysis": {
    "relevance_threshold": 0.6,       // Filtro m√°s estricto
    "insight_filter": "actionable",   // Excluye observaciones metodol√≥gicas
    "show_insight_classification": true
  }
}
```

Esto elimina:
- ‚ùå Contenido decorativo (logos, banners)
- ‚ùå Descripciones metodol√≥gicas ("El estudio abarca...")
- ‚ùå Informaci√≥n procedimental sin insights
- ‚úÖ Mantiene solo hallazgos y conclusiones accionables

### Casos de Uso por Filtro

| `insight_filter` | Uso Recomendado |
|------------------|-----------------|
| `"actionable"` | **Reportes ejecutivos** - Solo conclusiones √∫tiles |
| `"findings"` | **An√°lisis cuantitativo** - Solo datos con respaldo estad√≠stico |
| `"all"` | **Documentaci√≥n completa** - Incluye contexto metodol√≥gico |
| `"hypotheses"` | **Exploraci√≥n cualitativa** - Solo observaciones interpretativas |

**Tip**: El JSON siempre contiene TODOS los datos. Los filtros solo afectan el resumen Markdown.